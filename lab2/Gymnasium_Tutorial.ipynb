{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac53cf9-7bfa-4da8-9506-c2dba2dda92e",
   "metadata": {},
   "source": [
    "Lab 2 : Open AI Gymnasium\n",
    "----\n",
    "\n",
    "As we are steadily advancing towards Reinforcement Learning in class, it's time to get our hands dirty with another cool Python package. Gymnasium, originally developed by OpenAI is a useful tool that is commonly used for solving RL-related challenges. With Gymnasium, users can easily design, implement, and evaluate reinforcement learning algorithms by leveraging predefined environments such as classic control tasks, Atari 2600 games, and more. Furthermore, Gymnasium provides an easy API to implement your own environments!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ed948-05a8-4a3f-9a66-c2a754c8b329",
   "metadata": {},
   "source": [
    "First, let's get started with installing Gymnasium!\n",
    "\n",
    "Step 1. Make sure you have python and pip installed. Check the installation of python and pip using \n",
    "- `python --version` and `pip --version`\n",
    "If pip is not installed:\n",
    "- Follow the steps listed for your respective operating system at [Pip Docs - Installation](https://pip.pypa.io/en/stable/installation/).\n",
    "\n",
    "Step 2. Now execute `pip install gym` in your terminal to install gymnasium or run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3d3a92-0ace-4d2b-9389-93d9fd4699f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\danie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gym) (2.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gym) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\danie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gym) (0.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccaff9a-c81d-4889-9236-b65341252f47",
   "metadata": {},
   "source": [
    "Now to verify installation of gym execute the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7d2e68-590a-450e-8e64-a031afabe535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c4595-a2f2-4995-a65f-74d48bb57b48",
   "metadata": {},
   "source": [
    "Great! Now let's talk about environments! \n",
    "\n",
    "The fundamental building block of OpenAI Gym is the `Env` class. It is a Python class that implements a simulator that runs the  environment you want to train your agent in. Open AI Gym comes packed with a lot of environments, such as one where you can move a car up a hill, balance a swinging pendulum etc. Take a moment now to visit [Gymnasium - Farama](https://gymnasium.farama.org/) to see the complete list of environments, along with demonstrations of what the task in each environment is. \n",
    "\n",
    "In this lab, we will begin with the `MountainCar` environment. Our goal is to control a car on a track positioned between two mountains. The objective is to drive up the mountain on the right, but the car's engine lacks the power to climb it directly. To solve this problem, we require the car to make strategic back-and-forth movements to build momentum. \n",
    "\n",
    "Let's see how we can train our car to climb up the mountain using gymnasium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c64f01-9657-4071-a037-71919d671119",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb0da5d9-ba4b-4764-accf-1ca1e05948f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While creating our mountain car environment, render_mode is an optional argument. \n",
    "# It is used to render the environment visually when needed.\n",
    "# For more details, visit https://gymnasium.farama.org/api/env/\n",
    "\n",
    "env = gym.make('MountainCar-v0', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7abdf-d9b9-42b4-9a8c-2efa1997704d",
   "metadata": {},
   "source": [
    "In Reinforcement Learning, we think of two key terms - the `Observation Space` and `Action space`.\n",
    "\n",
    "The `Observation Space` is the set of all possible observations that an agent can receive from the environment. These observations provide information about the current state of the environment. Observations can be diverse and may include sensor readings, images, or any relevant data that helps the agent make decisions.\n",
    "\n",
    "For example, for an agent trying to learn how to shoot a target the observation space can include - the agent's current position or location, the position and movement of the target, information about obstacles or barriers in the environment if any, and the agent's ammunition status or the number of bullets remaining.\n",
    "\n",
    "The `Action Space` represents the set of possible actions that the agent can take to interact with the environment. These actions represent the decisions or movements that the agent can make to interact with the environment.\n",
    "\n",
    "For example for an agent trying to learn how to shoot a target the action space can include - adjusting the aim or direction of the firearm, pulling the trigger to shoot, reloading the firearm, and changing the stance or position of the agent.\n",
    "\n",
    "The basic structure of the environment is described by the observation_space and the action_space attributes of the Gym Env class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480cd8d0-0dfc-4d21-b5f4-48f74d1bb7a6",
   "metadata": {},
   "source": [
    "## To-do \n",
    "Can you guess what the observation space and state space of the mountain car problem would be? Write your answer below. Try to provide 2-3 examples for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0ae5a-1466-47a2-9a0f-fe36d6511653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR ANSWER HERE\n",
    "Observation Space:\n",
    "- Car's location\n",
    "- Car's speed\n",
    "\n",
    "Action space:\n",
    "- Pressing the gas pedal to accelerate\n",
    "- Switch direction (reversing)\n",
    "- Don't press gas pedal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d161a237-b07c-4228-8f41-e422a45ccc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "The action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "# Observation and action space for mountain-view problem\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(\"The observation space: {}\".format(obs_space))\n",
    "print(\"The action space: {}\".format(action_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e1260-0405-497b-b1a8-3c4033200966",
   "metadata": {},
   "source": [
    "The observation_space for our environment is a Box with shape (2,), and returns two lists with entries of type float32.\n",
    "The action_space was Discrete with shape (2). \n",
    "\n",
    "What do these actually mean? \n",
    "\n",
    "Both Box and Discrete are types of data structures called \"Spaces\" provided by Gym, modeling various aspects of the problem at hand. All of these data structures are derived from the gym.Space base class.\n",
    "\n",
    "Box, for instance, is used when modeling real-valued quantities, i.e. a continuous space. The printed output can be a bit tricky to read - the first list in the observation space above contains minimum values for the set of quantities that are modeled, and the second list contains the maxima. \n",
    "\n",
    "For this particular problem (Mountain Car), the values at index 0 within both lists refer to the minimum and maximum value of the car's position along the x-axis, i.e. the car will always be between x=-1.2 and x=0.6. The values at index 1 represent the range of the velocity, i.e. the car's speed will be between -0.07 and 0.07. Both these values are allowed to vary continuously with the precision of the float32 dtype.\n",
    "\n",
    "Discrete, on the other hand, signifies that there are a finite number of options to choose from. In this case, Discrete(3) represents the fact that the agent has three choices: 0: accelerate left, 1: don't accelerate, and 2: accelerate right. The easiest way to find descriptions for actions (and their indices) is to visit the [Gymnasium page for that task](https://gymnasium.farama.org/environments/classic_control/mountain_car/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65911af6-c32d-45bc-aa78-a5257e3b9195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Bound for Env Observation [0.6  0.07]\n",
      "Lower Bound for Env Observation [-1.2  -0.07]\n"
     ]
    }
   ],
   "source": [
    "print(\"Upper Bound for Env Observation\", env.observation_space.high)\n",
    "print(\"Lower Bound for Env Observation\", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0d771-dee2-4571-b337-1abb978f9549",
   "metadata": {},
   "source": [
    "You can set these upper/lower limits while defining your space, as well as when you are creating an environment.\n",
    "\n",
    "From here on, remember that an observation for the mountain car environment is a vector of two numbers, representing position and velocity respectively. The middle point between the two mountains in the environment is taken to be the origin, with the right being considered the positive direction and the left being the negative direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02de71b-4878-4222-ba60-262972798b87",
   "metadata": {},
   "source": [
    "Now let's talk about how the env class helps the agent interact with the environment!\n",
    "\n",
    "`reset`: This function returns the initial observation of the environment after placing the agent back in its starting state. Our first observation in any RL task implemented using Gymnasium must be obtained by calling this function. This function should also be called every time a terminal/end state is reached.\n",
    "`step`: This function takes an action as input, applies it to the environment, and returns the following:\n",
    "- `observation`: The current state of the environment after the action is taken.\n",
    "- `reward`: The reward obtained from the action.\n",
    "- `terminated`: Return true or false, depending on whether the agent has reached a terminal state (as defined under the task).\n",
    "- `truncated`: Determine if the truncation condition, often a time limit or agent going out of bounds, is satisfied. This can prompt an early episode termination before reaching a terminal state. Think of this as cases that may end a game preemptively.\n",
    "- `info`: Extra information for debugging or environment-specific details, such as lives remaining.\n",
    "\n",
    "Next, we demonstrate the step function, which is how we get the agent to execute an action in a Gymnasium environment. For now, we will simply pick a random action from the environment's action space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1898f7c-34f7-4501-abb2-acc459a90bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial observation is (array([-0.5259362,  0.       ], dtype=float32), {})\n",
      "The new observation is [-0.5249187   0.00101753]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment and see the initial observation\n",
    "obs = env.reset()\n",
    "print(\"The initial observation is {}\".format(obs))\n",
    "\n",
    "# Sample a random action from the entire action space\n",
    "random_action = env.action_space.sample()\n",
    "\n",
    "# # Take the action and get the new observation space\n",
    "new_obs, reward, terminated, truncated, info = env.step(random_action)\n",
    "print(\"The new observation is {}\".format(new_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e61c01-ae9a-4d66-923e-b77aa005d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pygame 2.6.1\n",
      "Uninstalling pygame-2.6.1:\n",
      "  Successfully uninstalled pygame-2.6.1\n",
      "Collecting pygame\n",
      "  Using cached pygame-2.6.1-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Using cached pygame-2.6.1-cp312-cp312-win_amd64.whl (10.6 MB)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'gym[classic_control]'\": Expected package name at the start of dependency specifier\n",
      "    'gym[classic_control]'\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# This step is optional and only needs to be executed if you want to render and view the environment. \n",
    "# May be finicky on MacOS. It's fine to skip it for now!\n",
    "!pip uninstall -y pygame\n",
    "!pip install pygame --pre\n",
    "!pip install 'gym[classic_control]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28d9d259-6933-420a-8201-a536429bec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "# only way to end a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1cd30-8d74-4d44-8bbf-422034a674af",
   "metadata": {},
   "source": [
    "# To-do\n",
    "Now it's your turn to try writing code to see how far up the hill this cart can go by taking random steps in this environment.\\\n",
    "Since we are not training the agent at all, we don't expect to see much progress, but this should give us a good idea of how gymnasium works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e95af7-3928-4a67-96f0-042eb1813e73",
   "metadata": {},
   "source": [
    "#### To Ponder:\n",
    "\n",
    "In the previous code block where we were taking actions, we didn't use the agent's state and reward to decide the best action from the new state. All the generated actions are random, and you'll be doing the same thing below. We'll learn how to train agents in lecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cef06417-1720-42fd-9045-0cef49e52bea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Render the env here (Rendering might take longer for the cell to execute. \u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Stop execution once you get a sense of what's happening and move on to the next part of the lab).\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(env\u001b[38;5;241m.\u001b[39mrender())\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# take random action (based on examples above)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\formatters.py:182\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    180\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\formatters.py:226\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    345\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    168\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 170\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\backend_bases.py:2175\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2172\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2175\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\figure.py:3162\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3159\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3162\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3165\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\axes\\_base.py:3137\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3135\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3137\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3140\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:653\u001b[0m, in \u001b[0;36m_ImageBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    651\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im, trans)\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 653\u001b[0m     im, l, b, trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_magnification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    656\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im)\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:952\u001b[0m, in \u001b[0;36mAxesImage.make_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    949\u001b[0m transformed_bbox \u001b[38;5;241m=\u001b[39m TransformedBbox(bbox, trans)\n\u001b[0;32m    950\u001b[0m clip \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_box() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mbbox) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_on()\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox)\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmagnification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munsampled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:567\u001b[0m, in \u001b[0;36m_ImageBase._make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    565\u001b[0m         output_alpha \u001b[38;5;241m=\u001b[39m _resample(  \u001b[38;5;66;03m# resample alpha channel\u001b[39;00m\n\u001b[0;32m    566\u001b[0m             \u001b[38;5;28mself\u001b[39m, A[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m], out_shape, t, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[1;32m--> 567\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# resample rgb channels\u001b[39;49;00m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_rgb_to_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m output_alpha  \u001b[38;5;66;03m# recombine rgb and alpha\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# output is now either a 2D array of normed (int or float) data\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# or an RGBA array of re-sampled input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:208\u001b[0m, in \u001b[0;36m_resample\u001b[1;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     resample \u001b[38;5;241m=\u001b[39m image_obj\u001b[38;5;241m.\u001b[39mget_resample()\n\u001b[1;32m--> 208\u001b[0m \u001b[43m_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_interpd_\u001b[49m\u001b[43m[\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m                \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m                \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimage_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_filternorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimage_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_filterrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "env_screen= None\n",
    "\n",
    "# Number of steps you run the agent for\n",
    "# This may take a few minutes to execute depending on the number of steps\n",
    "num_steps = 2000\n",
    "\n",
    "# reset the environment here\n",
    "''' YOUR CODE HERE '''\n",
    "env.reset()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Render the env here (Rendering might take longer for the cell to execute. \n",
    "    # Stop execution once you get a sense of what's happening and move on to the next part of the lab).\n",
    "    plt.imshow(env.render())\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True) \n",
    "    \n",
    "    # take random action (based on examples above)\n",
    "    ''' YOUR CODE HERE '''\n",
    "    random_action = env.action_space.sample()\n",
    "    \n",
    "    # apply the action using env.step here\n",
    "    ''' YOUR CODE HERE '''\n",
    "    env.step(random_action)\n",
    "    \n",
    "    # If the episode is finished (i.e., terminated or truncated), then reset the env and start another one;\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()\n",
    "        break\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8741d2e0-62c9-4884-92ea-c7eec4d23900",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Now that we have seen how to use gymnasium using its default environment, let's see how can we build a custom environment and perform actions in it. This particular custom environment is built using the gymnasium extension for Markov Decision Processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744f4c8-a757-45a1-9e64-627d1d88a589",
   "metadata": {},
   "source": [
    "Let's consider a 3x3 grid where the action space is to move up, down, left, or right. An action that takes you out of the grid is considered invalid. The red cells in the grid represent a reward of -20, the yellow cell has a reward of +5 and the green one has a reward of +10. Consider the green cell as the final goal state, which is where we want our agent to go. There is an equal probability of taking any valid action from a given cell. \n",
    "\n",
    "Here's how the grid is defined **(on a Euclidean plane)**:\n",
    "\n",
    "Cell 0 - 0,0 (start)\\\n",
    "Cell 1 - 0,1\\\n",
    "Cell 2 - 0,2\\\n",
    "Cell 3 - 1,0\\\n",
    "Cell 4 - 1,1\\\n",
    "Cell 5 - 1,2\\\n",
    "Cell 6 - 2,0 (goal)\\\n",
    "Cell 7 - 2,1\\\n",
    "Cell 8 - 2,2\n",
    "\n",
    "<div><img src=\"./grid.png\", style=\"width:400px\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df2e21d5-cf0c-48ca-a5ec-5b1be49ed96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matrix-mdp-gym\n",
      "  Downloading matrix_mdp_gym-1.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting gymnasium>=0.26.2 (from matrix-mdp-gym)\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matrix-mdp-gym) (2.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium>=0.26.2->matrix-mdp-gym) (3.0.0)\n",
      "Collecting typing-extensions>=4.3.0 (from gymnasium>=0.26.2->matrix-mdp-gym)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.26.2->matrix-mdp-gym)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Downloading matrix_mdp_gym-1.1.1-py3-none-any.whl (6.0 kB)\n",
      "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "   ---------------------------------------- 0.0/958.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 958.1/958.1 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: farama-notifications, typing-extensions, gymnasium, matrix-mdp-gym\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 matrix-mdp-gym-1.1.1 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matrix-mdp-gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be1e5434-274a-4e43-8424-a8543f97b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_states = 9 # total number of cells\n",
    "num_actions = 4 # up, down, left, right\n",
    "num_terminal_states = 1 # initilaise the number of terminal goal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5758daba-44c3-4f45-b859-7f5958185ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'up', 1: 'down', 2: 'left', 3: 'right'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To-do:\n",
    "# Initialise the action map as a dictionary, just to save human readable labels. 0 maps to 'up', 1 to 'down', 2 to 'left', and 3 to 'right'.\n",
    "A = ''' Write Code '''\n",
    "{0: \"up\",\n",
    " 1: \"down\",\n",
    " 2: \"left\",\n",
    " 3: \"right\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5fe8bc81-5b56-498d-bea9-41891a5f5674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do: fill in and complete the state_action_map here, this is a map of all the valid actions from a given state. \n",
    "# Values for cell 0 and 6 are filled in for you\n",
    "# (from cell 0 we can go to the cell above it, or the cell to its right. \n",
    "# The action map values, therefore, are 0 and 3. For cell 6, since this state is terminal, there are no actions from it.\n",
    "\n",
    "# While we are hardcoding this for now, you should consider writing code \n",
    "# that generates this map using the rules of your environment in general.\n",
    "\n",
    "states_actions_map = {\n",
    "    0: [0, 3],\n",
    "    # COMPLETE THE MAP\n",
    "    1: [0, 2, 3],\n",
    "    2: [0,2],\n",
    "    3: [0, 1, 3],\n",
    "    4: [0, 1, 2, 3],\n",
    "    5: [0, 1, 2],\n",
    "    6: [],\n",
    "    7: [1, 2, 3],\n",
    "    8: [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a1f95d0-b87f-4737-b64f-29ada8813b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize transition and reward matrices.\n",
    "\n",
    "T = np.zeros((num_states, num_states, num_actions))\n",
    "R = np.zeros((num_states, num_states, num_actions))\n",
    "\n",
    "# 2. Fill in the transition matrix with the correct values.\n",
    "\n",
    "    # The matrix T represents transition probabilities, i.e., the probability of moving to state j from state i using action a. \n",
    "    # In uncertain environments, an action may have a small probability of failing and leading you to a different state than intended.\n",
    "    # For now, assume that the probability of failure is 0, i.e., an up action, for instance, \n",
    "    # will always take you to the cell above your current state, as long as such a cell exists. \n",
    "\n",
    "    # Note that T is a 3-dimensional matrix. Entries should be made at the index [new_state][current_state][action].\n",
    "    # For example, T[1][0][3] = 1 means that if we take action 3 (right) from cell 0 (start), the probability of reaching the cell 1 is 1.\n",
    "    # Use numpy operations to fill in the correct values in the matrix T.\n",
    "    \n",
    "'''\n",
    "YOUR CODE HERE\n",
    "'''\n",
    "for new_state in range(num_states):\n",
    "    for current_state in range(num_states):\n",
    "        for action in range(num_actions):\n",
    "            if action not in states_actions_map[current_state]:\n",
    "                continue\n",
    "\n",
    "            if action == 0 and (current_state + 3 == new_state):\n",
    "                T[new_state][current_state][action] = 1\n",
    "            \n",
    "            if action == 1 and (current_state - 3 == new_state):\n",
    "                T[new_state][current_state][action] = 1\n",
    "\n",
    "            if action == 2 and (current_state - 1 == new_state):\n",
    "                T[new_state][current_state][action] = 1\n",
    "            \n",
    "            if action == 3 and (current_state + 1 == new_state):\n",
    "                T[new_state][current_state][action] = 1\n",
    "\n",
    "# 3. Fill in the reward matrix with the correct values.\n",
    "\n",
    "    # The matrix R represents the rewards obtained by moving to state j from state i using action a. \n",
    "    # The red cells in the grid have a reward of -20, the yellow cell has a reward of +5, and the green one has a reward of +10.\n",
    "    # Assume rewards don't depend on the action used or the cell from which the agent moved to one of these cells for now.\n",
    "\n",
    "    # Entries should once again be made at the index [new_state][current_state][action].\n",
    "    # For example, R[2][1][3] = -20 indicates that if we take action 3 from cell 1 and reach cell 2, the reward is -20.\n",
    "    # Update the entries in the matrix R with the correct values below. \n",
    "\n",
    "for new_state in range(num_states):\n",
    "    for current_state in range(num_states):\n",
    "        for action in range(num_actions):\n",
    "            if T[new_state][current_state][action] == 1:\n",
    "                if new_state == 6:\n",
    "                    R[new_state][current_state][action] = 10\n",
    "                if new_state == 8:\n",
    "                    R[new_state][current_state][action] = -20\n",
    "                if new_state == 5:\n",
    "                    R[new_state][current_state][action] = 5\n",
    "                if new_state == 2:\n",
    "                    R[new_state][current_state][action] = -20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6aa0769d-4d9a-461f-beb0-1e00cf8dd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_0 is simply the initial probability distribution. This represents where your agent is at the beginning.\n",
    "# If there is only one possible start state, the probability distribution is simply a one-hot vector,\n",
    "# where the probability at the start state is 1 and 0 elsewhere.\n",
    "\n",
    "import numpy as np\n",
    "''' Write Start state '''\n",
    "P_0 = np.zeros(9)\n",
    "P_0[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "515f2f0d-09b1-4bad-9163-73c901ce7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matrix_mdp\n",
    "import gymnasium as gym\n",
    "env = gym.make('matrix_mdp/MatrixMDP-v0', p_0=P_0, p=T, r=R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca894307-9976-4215-bc81-c751fc00d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we reset the environment and get the initial observation.\n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c9c72-19ec-4995-828f-a74b7a32ed3b",
   "metadata": {},
   "source": [
    "Below, write the code for random exploration, i.e. randomly choosing an action at each time step and executing it.\n",
    "\n",
    "A random action is simply a random integer between 0 and the number of actions (num_actions not inclusive).\n",
    "However, you should make sure that the chosen action can actually be taken from the current state (i.e., the chosen action is valid).\n",
    "\n",
    "Keep track of the total reward in each episode, and reset the environment when the episode terminates.\n",
    "\n",
    "Print the average reward obtained over 10000 episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f2d1662-ba33-4f01-aec6-88be1cfa8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting total reward as zero\n",
    "total_rewards = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d33a4a4-8b6b-452e-bc71-ec6adfdda8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward obtained:  -49.08830453046151\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# To-Do:\n",
    "# For each episode, collect the reward the agent earns and store it.\n",
    "# After the end of all 10000 episodes, we are going to take the average reward earned by the agent.\n",
    "\n",
    "reward_list = []\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    observation, info = env.reset()\n",
    "    # print(\"initial obs: \", observation)\n",
    "    total_rewards = 0\n",
    "    while True:\n",
    "        # Pick an action using the random Python module random until we have a valid action for that cell\n",
    "        # Hint: use states_actions_map in conjunction with the random module\n",
    "        ''' Write Code '''\n",
    "        random_action = random.randint(0,3)\n",
    "        while random_action not in states_actions_map[observation]:\n",
    "            random_action = random.randint(0,3)\n",
    "        \n",
    "        # Get a new observation, reward, terminated and other information here using the env.step() function\n",
    "        ''' Write Code '''\n",
    "        # print(\"Action: \", random_action)\n",
    "        observation, reward, terminated, truncated, info = env.step(random_action)\n",
    "        # print(\"observation, reward: \", observation, reward)\n",
    "        # print(\"terminated: \", terminated)\n",
    "        # Update rewards\n",
    "        ''' Write Code '''\n",
    "        total_rewards += reward\n",
    "\n",
    "\n",
    "        # break this loop if we have reached an end state\n",
    "        if terminated:\n",
    "            break\n",
    "        reward_list.append(total_rewards)\n",
    "\n",
    "# calculate and print the average reward here\n",
    "avg_reward = sum(reward_list) / len(reward_list)\n",
    "print(\"Average reward obtained: \", avg_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b22b01-2c98-4ad3-b9c6-6f1d9416868d",
   "metadata": {},
   "source": [
    "Hope this lab helped you understand how to set up and navigate an environment in Gymnasium. \n",
    "As always, please don't hesitate to reach out to the instructor or the TAs if you have any questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
